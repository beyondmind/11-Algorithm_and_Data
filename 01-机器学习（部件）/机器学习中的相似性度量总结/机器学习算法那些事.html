<!DOCTYPE html>
<!-- saved from url=(0061)https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html -->
<html lang="zh-cn"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="referrer" content="origin">
<title>机器学习中的相似性度量 - 苍梧 - 博客园</title>
<meta property="og:description" content="在做分类时常常需要估算不同样本之间的相似性度量(SimilarityMeasurement)，这时通常采用的方法就是计算样本间的“距离”(Distance)。采用什么样的方法计算距离是很讲究，甚至关系">
<link type="text/css" rel="stylesheet" href="./机器学习算法那些事_files/blog-common.css">
<link id="MainCss" type="text/css" rel="stylesheet" href="./机器学习算法那些事_files/bundle-HabaHaba.css">
<link id="mobile-style" media="only screen and (max-width: 767px)" type="text/css" rel="stylesheet" href="./机器学习算法那些事_files/bundle-HabaHaba-mobile.css">
<link title="RSS" type="application/rss+xml" rel="alternate" href="https://www.cnblogs.com/heaad/rss">
<link title="RSD" type="application/rsd+xml" rel="EditURI" href="https://www.cnblogs.com/heaad/rsd.xml">
<link type="application/wlwmanifest+xml" rel="wlwmanifest" href="https://www.cnblogs.com/heaad/wlwmanifest.xml">
<script src="./机器学习算法那些事_files/f.txt"></script><script src="./机器学习算法那些事_files/amp4ads-host-v0.js"></script><script src="./机器学习算法那些事_files/pubads_impl_rendering_275.js"></script><script async="" src="./机器学习算法那些事_files/analytics.js"></script><script src="./机器学习算法那些事_files/jquery-2.2.0.min.js"></script>
<script type="text/javascript">var currentBlogApp = 'heaad', cb_enable_mathjax=false;var isLogined=false;</script>
<script src="./机器学习算法那些事_files/blog-common.js" type="text/javascript"></script>
<link rel="preload" href="./机器学习算法那些事_files/f(1).txt" as="script"><script type="text/javascript" src="./机器学习算法那些事_files/f(1).txt"></script><script src="./机器学习算法那些事_files/pubads_impl_275.js" async=""></script><link rel="prefetch" href="https://tpc.googlesyndication.com/safeframe/1-0-31/html/container.html"></head>
<body>
<a name="top"></a>

<table width="100%" class="Framework" cellspacing="0" cellpadding="0">
	<tbody><tr>
		<td colspan="2">
			
<div id="top">
<table width="100%" cellpadding="8" cellspacing="0">
	<tbody><tr>
		<td nowrap="">
			<h1><a id="Header1_HeaderTitle" class="headermaintitle" href="https://www.cnblogs.com/heaad/"></a></h1>
			
		</td>
	</tr>
</tbody></table>
</div>
<div id="sub"><div id="blog_stats">
<div class="BlogStats">posts - 19, comments - 314, trackbacks - 0, articles - 0</div></div></div>


</td>
	</tr>
	<tr>
		<td class="LeftCell">
			<div id="leftmenu">
                
                    
<h3>导航</h3>
<ul>
	<li>
		<a id="blog_nav_sitehome" href="https://www.cnblogs.com/">博客园</a>
	</li><li>
		<a id="blog_nav_myhome" href="https://www.cnblogs.com/heaad/">首页</a>
	</li><li>
		<a id="blog_nav_newpost" rel="nofollow" href="https://i.cnblogs.com/EditPosts.aspx?opt=1">新随笔</a>
	</li><li>
		<a id="blog_nav_contact" accesskey="9" rel="nofollow" href="https://msg.cnblogs.com/send/%E8%8B%8D%E6%A2%A7">联系</a>
	</li><li>
		<a id="blog_nav_rss_image" href="https://www.cnblogs.com/heaad/rss"><img src="./机器学习算法那些事_files/xml.gif" alt="订阅"></a><a id="blog_nav_rss" href="https://www.cnblogs.com/heaad/rss">订阅</a>
	</li><li>
		<a id="blog_nav_admin" rel="nofollow" href="https://i.cnblogs.com/">管理</a></li>
</ul>

                    
<h3>公告</h3>
<div id="news">
	<div id="blog-news"><div id="profile_block">昵称：<a href="https://home.cnblogs.com/u/heaad/">苍梧</a><br>园龄：<a href="https://home.cnblogs.com/u/heaad/" title="入园时间：2009-05-01">9年6个月</a><br>粉丝：<a href="https://home.cnblogs.com/u/heaad/followers/">1053</a><br>关注：<a href="https://home.cnblogs.com/u/heaad/followees/">2</a><div id="p_b_follow"><a href="javascript:void(0);" onclick="follow(&#39;323033f4-1936-de11-9510-001cf0cd104b&#39;)">+加关注</a></div><script>getFollowStatus('323033f4-1936-de11-9510-001cf0cd104b')</script></div></div><script type="text/javascript">loadBlogNews();</script>
</div>
                    <div id="blog-calendar" style=""><table id="blogCalendar" class="Cal" cellspacing="0" cellpadding="0" title="Calendar">
	<tbody><tr><td colspan="7"><table class="CalTitle" cellspacing="0">
		<tbody><tr><td class="CalNextPrev"><a href="javascript:void(0);" onclick="loadBlogCalendar(&#39;2018/10/01&#39;);return false;">&lt;</a></td><td align="center">2018年11月</td><td class="CalNextPrev" align="right"><a href="javascript:void(0);" onclick="loadBlogCalendar(&#39;2018/12/01&#39;);return false;">&gt;</a></td></tr>
	</tbody></table></td></tr><tr><th class="CalDayHeader" align="center" abbr="日" scope="col">日</th><th class="CalDayHeader" align="center" abbr="一" scope="col">一</th><th class="CalDayHeader" align="center" abbr="二" scope="col">二</th><th class="CalDayHeader" align="center" abbr="三" scope="col">三</th><th class="CalDayHeader" align="center" abbr="四" scope="col">四</th><th class="CalDayHeader" align="center" abbr="五" scope="col">五</th><th class="CalDayHeader" align="center" abbr="六" scope="col">六</th></tr><tr><td class="CalOtherMonthDay" align="center">28</td><td class="CalOtherMonthDay" align="center">29</td><td class="CalOtherMonthDay" align="center">30</td><td class="CalOtherMonthDay" align="center">31</td><td align="center">1</td><td align="center">2</td><td class="CalWeekendDay" align="center">3</td></tr><tr><td class="CalWeekendDay" align="center">4</td><td align="center">5</td><td align="center">6</td><td align="center">7</td><td align="center">8</td><td align="center">9</td><td class="CalWeekendDay" align="center">10</td></tr><tr><td class="CalWeekendDay" align="center">11</td><td align="center">12</td><td align="center">13</td><td align="center">14</td><td align="center">15</td><td align="center">16</td><td class="CalWeekendDay" align="center">17</td></tr><tr><td class="CalWeekendDay" align="center">18</td><td align="center">19</td><td align="center">20</td><td align="center">21</td><td align="center">22</td><td align="center">23</td><td class="CalWeekendDay" align="center">24</td></tr><tr><td class="CalWeekendDay" align="center">25</td><td class="CalTodayDay" align="center">26</td><td align="center">27</td><td align="center">28</td><td align="center">29</td><td align="center">30</td><td class="CalOtherMonthDay" align="center">1</td></tr><tr><td class="CalOtherMonthDay" align="center">2</td><td class="CalOtherMonthDay" align="center">3</td><td class="CalOtherMonthDay" align="center">4</td><td class="CalOtherMonthDay" align="center">5</td><td class="CalOtherMonthDay" align="center">6</td><td class="CalOtherMonthDay" align="center">7</td><td class="CalOtherMonthDay" align="center">8</td></tr>
</tbody></table></div><script type="text/javascript">loadBlogDefaultCalendar();</script>
                    <div id="blog-sidecolumn"><div id="sidebar_search" class="sidebar-block">
<div id="sidebar_search" class="mySearch">
<h3 class="catListTitle">搜索</h3>
<div id="sidebar_search_box">
<div id="widget_my_zzk" class="div_my_zzk"><input type="text" id="q" onkeydown="return zzk_go_enter(event);" class="input_my_zzk">&nbsp;<input onclick="zzk_go()" type="button" value="找找看" id="btnZzk" class="btn_my_zzk"></div>
<div id="widget_my_google" class="div_my_zzk"><input type="text" name="google_q" id="google_q" onkeydown="return google_go_enter(event)" class="input_my_zzk">&nbsp;<input onclick="google_go()" type="button" value="谷歌搜索" class="btn_my_zzk"></div>
</div>
</div>

</div><div id="sidebar_shortcut" class="sidebar-block">
<h3 class="catListTitle">常用链接</h3>
<ul>
<li><a href="https://www.cnblogs.com/heaad/p/" title="我的博客的随笔列表">我的随笔</a></li><li><a href="https://www.cnblogs.com/heaad/MyComments.html" title="我发表过的评论列表">我的评论</a></li><li><a href="https://www.cnblogs.com/heaad/OtherPosts.html" title="我评论过的随笔列表">我的参与</a></li><li><a href="https://www.cnblogs.com/heaad/RecentComments.html" title="我的博客的评论列表">最新评论</a></li><li><a href="https://www.cnblogs.com/heaad/tag/" title="我的博客的标签列表">我的标签</a></li>
</ul>
<div id="itemListLin_con" style="display:none;">

</div></div><div id="sidebar_recentposts" class="sidebar-block">
<h3 class="catListTitle">最新随笔</h3>
<div class="RecentComment" id="RecentPosts">
<ul style="word-break:break-all">
<li><a href="https://www.cnblogs.com/heaad/archive/2011/03/09/1978254.html">1. Let’s Play Games!</a></li><li><a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html">2. 机器学习中的相似性度量</a></li><li><a href="https://www.cnblogs.com/heaad/archive/2011/03/07/1976443.html">3. 神经网络编程入门</a></li><li><a href="https://www.cnblogs.com/heaad/archive/2011/01/18/1938499.html">4. MPEG-7实例入门</a></li><li><a href="https://www.cnblogs.com/heaad/archive/2011/01/02/1924195.html">5. 那些优雅的数据结构(1) : BloomFilter——大规模数据处理利器</a></li><li><a href="https://www.cnblogs.com/heaad/archive/2011/01/02/1924088.html">6. 特征选择常用算法综述</a></li><li><a href="https://www.cnblogs.com/heaad/archive/2010/12/23/1914725.html">7. 遗传算法入门</a></li><li><a href="https://www.cnblogs.com/heaad/archive/2010/12/22/1913733.html">8. 二进制与三进制的那些趣题</a></li><li><a href="https://www.cnblogs.com/heaad/archive/2010/12/20/1912049.html">9. 色彩学基础知识</a></li><li><a href="https://www.cnblogs.com/heaad/archive/2010/12/20/1911614.html">10. 大白话解析模拟退火算法</a></li>
</ul>
</div>
</div><div id="sidebar_categories">
		<h3>随笔分类<span style="font-size:11px;font-weight:normal">(19)</span></h3>
		
				<ul>
			
				<li><a id="CatList_LinkList_0_Link_0" href="https://www.cnblogs.com/heaad/category/199818.html">Linux相关(5)</a></li>
			
				<li><a id="CatList_LinkList_0_Link_1" href="https://www.cnblogs.com/heaad/category/271789.html">多媒体·信号处理(2)</a></li>
			
				<li><a id="CatList_LinkList_0_Link_2" href="https://www.cnblogs.com/heaad/category/272649.html">机器学习(5)</a></li>
			
				<li><a id="CatList_LinkList_0_Link_3" href="https://www.cnblogs.com/heaad/category/200143.html">数据结构·算法(4)</a></li>
			
				<li><a id="CatList_LinkList_0_Link_4" href="https://www.cnblogs.com/heaad/category/271214.html">数学·趣题(3)</a></li>
			
				</ul>
			
	
		<h3>随笔档案<span style="font-size:11px;font-weight:normal">(19)</span></h3>
		
				<ul>
			
				<li><a id="CatList_LinkList_1_Link_0" href="https://www.cnblogs.com/heaad/archive/2011/03.html">2011年3月 (3)</a></li>
			
				<li><a id="CatList_LinkList_1_Link_1" href="https://www.cnblogs.com/heaad/archive/2011/01.html">2011年1月 (3)</a></li>
			
				<li><a id="CatList_LinkList_1_Link_2" href="https://www.cnblogs.com/heaad/archive/2010/12.html">2010年12月 (4)</a></li>
			
				<li><a id="CatList_LinkList_1_Link_3" href="https://www.cnblogs.com/heaad/archive/2010/11.html">2010年11月 (2)</a></li>
			
				<li><a id="CatList_LinkList_1_Link_4" href="https://www.cnblogs.com/heaad/archive/2010/08.html">2010年8月 (1)</a></li>
			
				<li><a id="CatList_LinkList_1_Link_5" href="https://www.cnblogs.com/heaad/archive/2010/07.html">2010年7月 (2)</a></li>
			
				<li><a id="CatList_LinkList_1_Link_6" href="https://www.cnblogs.com/heaad/archive/2010/06.html">2010年6月 (1)</a></li>
			
				<li><a id="CatList_LinkList_1_Link_7" href="https://www.cnblogs.com/heaad/archive/2010/05.html">2010年5月 (1)</a></li>
			
				<li><a id="CatList_LinkList_1_Link_8" href="https://www.cnblogs.com/heaad/archive/2009/08.html">2009年8月 (1)</a></li>
			
				<li><a id="CatList_LinkList_1_Link_9" href="https://www.cnblogs.com/heaad/archive/2009/05.html">2009年5月 (1)</a></li>
			
				</ul>
			
	</div><div id="sidebar_recentcomments" class="sidebar-block"><div id="recent_comments_wrap">
<h3 class="catListTitle">最新评论</h3>
<div class="RecentComment" id="RecentComments">
	<div id="RecentCommentsBlock"><ul>
        <li class="recent_comment_title"><a href="https://www.cnblogs.com/heaad/archive/2011/03/07/1976443.html#4054852">1. Re:神经网络编程入门</a></li>
        <li class="recent_comment_body">好文！</li>
        <li class="recent_comment_author">--灰丶猫</li>
        <li class="recent_comment_title"><a href="https://www.cnblogs.com/heaad/archive/2010/07/17/1779829.html#4021521">2. Re:U-Boot启动过程完全分析</a></li>
        <li class="recent_comment_body">写的很好，谢谢无私分享。</li>
        <li class="recent_comment_author">--好肥的波哥</li>
        <li class="recent_comment_title"><a href="https://www.cnblogs.com/heaad/archive/2011/03/07/1976443.html#4009686">3. Re:神经网络编程入门</a></li>
        <li class="recent_comment_body">初学者，感谢博主</li>
        <li class="recent_comment_author">--yuhailong001</li>
        <li class="recent_comment_title"><a href="https://www.cnblogs.com/heaad/archive/2010/06/06/1752468.html#3996292">4. Re:连连看算法及源代码</a></li>
        <li class="recent_comment_body">不错</li>
        <li class="recent_comment_author">--醉语清风</li>
        <li class="recent_comment_title"><a href="https://www.cnblogs.com/heaad/archive/2010/06/06/1752468.html#3952128">5. Re:连连看算法及源代码</a></li>
        <li class="recent_comment_body">dddddd</li>
        <li class="recent_comment_author">--key_xie</li>
</ul>
</div>
</div>
</div></div></div><script type="text/javascript">loadBlogSideColumn();</script>
                	        
			</div>
		</td>
		<td class="MainCell" width="100%">
			<div id="main">
				
<div id="post_detail">
	<div class="post">
		<div class="posthead">
			<h2>
				<a id="cb_post_title_url" class="singleposttitle" href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html">机器学习中的相似性度量</a>
			</h2>
 			Posted on <span id="post-date">2011-03-08 23:42</span> <a href="https://www.cnblogs.com/heaad/">苍梧</a> 阅读(<span id="post_view_count">93150</span>) 评论(<span id="post_comment_count">19</span>)  <a href="https://i.cnblogs.com/EditPosts.aspx?postid=1977733" rel="nofollow">编辑</a> <a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#" onclick="AddToWz(1977733);return false;">收藏</a>
			<script type="text/javascript">var allowComments=true,cb_blogId=55806,cb_entryId=1977733,cb_blogApp=currentBlogApp,cb_blogUserGuid='323033f4-1936-de11-9510-001cf0cd104b',cb_entryCreatedDate='2011/3/8 23:42:00';loadViewCount(cb_entryId);var cb_postType=1;</script>
			
		</div>
		<div class="postbody"><div id="cnblogs_post_body" class="blogpost-body"><p><span style="font-size: 16px;">　　在做分类时常常需要估算不同样本之间的相似性度量(Similarity
Measurement)，这时通常采用的方法就是计算样本间的“距离”(Distance)。采用什么样的方法计算距离是很讲究，甚至关系到分类的正确与否。</span></p>
<p><span style="font-size: 16px;">　　本文的目的就是对常用的相似性度量作一个总结。</span></p>
<p><span style="font-size: 16px;"><br></span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">本文目录：</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">1.
欧氏距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">2.
曼哈顿距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">3. 切比雪夫距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">4. 闵可夫斯基距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">5.
标准化欧氏距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">6.
马氏距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">7.
夹角余弦</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">8.
汉明距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">9.
杰卡德距离
&amp; 杰卡德相似系数</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">10.
相关系数
&amp; 相关距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">11.
信息熵</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>1. </b><b>欧氏距离</b><b>(Euclidean
Distance)</b></span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 欧氏距离是最易于理解的一种距离计算方法，源自欧氏空间中两点间的距离公式。</span></p>
<p><span style="font-size: 16px;">(1)二维平面上两点a(x1,y1)与b(x2,y2)间的欧氏距离：</span></p>
<p><span style="font-size: 16px;">&nbsp;<img src="./机器学习算法那些事_files/2011030823203337.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">(2)三维空间两点a(x1,y1,z1)与b(x2,y2,z2)间的欧氏距离：</span></p>
<p><span style="font-size: 16px;">&nbsp;<img src="./机器学习算法那些事_files/2011030823204453.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">(3)两个n维向量a(x11,x12,…,x1n)与 b(x21,x22,…,x2n)间的欧氏距离：</span></p>
<p><span style="font-size: 16px;">&nbsp;<img src="./机器学习算法那些事_files/2011030823205483.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">　　也可以用表示成向量运算的形式：</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823211360.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p align="center">&nbsp;</p>
<p><span style="font-size: 16px;">(4)Matlab计算欧氏距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">Matlab计算距离主要使用pdist函数。若X是一个M×N的矩阵，则pdist(X)将X矩阵M行的每一行作为一个N维向量，然后计算这M个向量两两间的距离。</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">例子：计算向量(0,0)、(1,0)、(0,2)两两间的欧式距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">X
= [0 0 ; 1 0 ; 0 2]</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
= pdist(X,'euclidean')</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">结果：</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
=</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp; 1.0000&nbsp;&nbsp;&nbsp;
2.0000&nbsp;&nbsp;&nbsp; 2.2361</span></p>
<p style="padding-left: 30px;">&nbsp;</p>
<p style="padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>2. </b><b>曼哈顿距离</b><b>(Manhattan
Distance)</b></span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 从名字就可以猜出这种距离的计算方法了。想象你在曼哈顿要从一个十字路口开车到另外一个十字路口，驾驶距离是两点间的直线距离吗？显然不是，除非你能穿越大楼。实际驾驶距离就是这个“曼哈顿距离”。而这也是曼哈顿距离名称的来源， 曼哈顿距离也称为<b>城市街区距离</b><b>(City
Block distance)</b>。</span></p>
<p><span style="font-size: 16px;">(1)二维平面两点a(x1,y1)与b(x2,y2)间的曼哈顿距离</span></p>
<p><span style="font-size: 16px;">&nbsp;<img src="./机器学习算法那些事_files/2011030823213652.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">(2)两个n维向量a(x11,x12,…,x1n)与
b(x21,x22,…,x2n)间的曼哈顿距离</span></p>
<p><span style="font-size: 16px;">&nbsp;<img src="./机器学习算法那些事_files/2011030823231354.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">(3)
Matlab计算曼哈顿距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">例子：计算向量(0,0)、(1,0)、(0,2)两两间的曼哈顿距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">X
= [0 0 ; 1 0 ; 0 2]</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
= pdist(X, 'cityblock')</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">结果：</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
=</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;
2&nbsp;&nbsp;&nbsp;&nbsp; 3</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>3. </b><b>切比雪夫距离</b><b> ( Chebyshev Distance ) </b></span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 国际象棋玩过么？国王走一步能够移动到相邻的8个方格中的任意一个。那么国王从格子(x1,y1)走到格子(x2,y2)最少需要多少步？自己走走试试。你会发现最少步数总是max(
| x2-x1 | , | y2-y1 | ) 步
。有一种类似的一种距离度量方法叫切比雪夫距离。</span></p>
<p><span style="font-size: 16px;">(1)二维平面两点a(x1,y1)与b(x2,y2)间的切比雪夫距离</span></p>
<p align="center"><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823234117.png">&nbsp;</span></p>
<p><span style="font-size: 16px;">(2)两个n维向量a(x11,x12,…,x1n)与
b(x21,x22,…,x2n)间的切比雪夫距离</span></p>
<p><span style="font-size: 16px;">&nbsp;<img src="./机器学习算法那些事_files/2011030823235870.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">　　这个公式的另一种等价形式是</span></p>
<p><span style="font-size: 16px;">&nbsp;<img src="./机器学习算法那些事_files/2011030823242560.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 看不出两个公式是等价的？提示一下：试试用放缩法和夹逼法则来证明。</span></p>
<p><span style="font-size: 16px;">(3)Matlab计算切比雪夫距离</span></p>
<p style="text-align: left; padding-left: 30px;"><span style="font-size: 16px;">例子：计算向量(0,0)、(1,0)、(0,2)两两间的切比雪夫距离</span></p>
<p style="text-align: left; padding-left: 30px;"><span style="font-size: 16px;">X
= [0 0 ; 1 0 ; 0 2]</span></p>
<p style="text-align: left; padding-left: 30px;"><span style="font-size: 16px;">D
= pdist(X, 'chebychev')</span></p>
<p style="text-align: left; padding-left: 30px;"><span style="font-size: 16px;">结果：</span></p>
<p style="text-align: left; padding-left: 30px;"><span style="font-size: 16px;">D
=</span></p>
<p style="text-align: left; padding-left: 30px;"><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;
2&nbsp;&nbsp;&nbsp;&nbsp; 2</span></p>
<p style="text-align: left; padding-left: 30px;">&nbsp;</p>
<p style="text-align: left; padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>4. </b><b>闵可夫斯基距离</b><b>(Minkowski
Distance)</b></span></p>
<p><span style="font-size: 16px;">闵氏距离不是一种距离，而是一组距离的定义。</span></p>
<p><span style="font-size: 16px;">(1)
闵氏距离的定义</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 两个n维变量a(x11,x12,…,x1n)与
b(x21,x22,…,x2n)间的闵可夫斯基距离定义为：</span></p>
<p><span style="font-size: 16px;">&nbsp;<img src="./机器学习算法那些事_files/2011030823244080.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">其中p是一个变参数。</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">当p=1时，就是曼哈顿距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">当p=2时，就是欧氏距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">当p→∞时，就是切比雪夫距离</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 根据变参数的不同，闵氏距离可以表示一类的距离。</span></p>
<p><span style="font-size: 16px;">(2)闵氏距离的缺点</span></p>
<p><span style="font-size: 16px;">　　闵氏距离，包括曼哈顿距离、欧氏距离和切比雪夫距离都存在明显的缺点。</span></p>
<p><span style="font-size: 16px;">　　举个例子：二维样本(身高,体重)，其中身高范围是150~190，体重范围是50~60，有三个样本：a(180,50)，b(190,50)，c(180,60)。那么a与b之间的闵氏距离（无论是曼哈顿距离、欧氏距离或切比雪夫距离）等于a与c之间的闵氏距离，但是身高的10cm真的等价于体重的10kg么？因此用闵氏距离来衡量这些样本间的相似度很有问题。</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 简单说来，闵氏距离的缺点主要有两个：(1)将各个分量的量纲(scale)，也就是“单位”当作相同的看待了。(2)没有考虑各个分量的分布（期望，方差等)可能是不同的。</span></p>
<p><span style="font-size: 16px;">(3)Matlab计算闵氏距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">例子：计算向量(0,0)、(1,0)、(0,2)两两间的闵氏距离（以变参数为2的欧氏距离为例）</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">X
= [0 0 ; 1 0 ; 0 2]</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
= pdist(X,'minkowski',2)</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">结果：</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
=</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp; 1.0000&nbsp;&nbsp;&nbsp;
2.0000&nbsp;&nbsp;&nbsp; 2.2361</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>5. </b><b>标准化欧氏距离</b><b>
(Standardized Euclidean distance )</b></span></p>
<p><span style="font-size: 16px;">(1)标准欧氏距离的定义</span></p>
<p><span style="font-size: 16px;">　　标准化欧氏距离是针对简单欧氏距离的缺点而作的一种改进方案。标准欧氏距离的思路：既然数据各维分量的分布不一样，好吧！那我先将各个分量都“标准化”到均值、方差相等吧。均值和方差标准化到多少呢？这里先复习点统计学知识吧，假设样本集X的均值(mean)为m，标准差(standard
deviation)为s，那么X的“标准化变量”表示为：</span></p>
<p><span style="font-size: 16px;">　　而且标准化变量的数学期望为0，方差为1。因此样本集的标准化过程(standardization)用公式描述就是：</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823264688.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">　　标准化后的值 =&nbsp; ( 标准化前的值&nbsp; － 分量的均值 ) /分量的标准差</span></p>
<p><span style="font-size: 16px;">　　经过简单的推导就可以得到两个n维向量a(x11,x12,…,x1n)与
b(x21,x22,…,x2n)间的标准化欧氏距离的公式：</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823272054.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">　　如果将方差的倒数看成是一个权重，这个公式可以看成是一种<b>加权欧氏距离</b><b>(Weighted
Euclidean distance)</b>。</span></p>
<p><span style="font-size: 16px;">(2)Matlab计算标准化欧氏距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">例子：计算向量(0,0)、(1,0)、(0,2)两两间的标准化欧氏距离 (假设两个分量的标准差分别为0.5和1)</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">X
= [0 0 ; 1 0 ; 0 2]</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
= pdist(X, 'seuclidean',[0.5,1])</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">结果：</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
=</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp; 2.0000&nbsp;&nbsp;&nbsp;
2.0000&nbsp;&nbsp;&nbsp; 2.8284</span></p>
<p><span style="font-size: 16px;"><b>&nbsp;</b></span></p>
<p><span style="font-size: 16px;"><b><br></b></span></p>
<p><span style="font-size: 16px;"><b>6. </b><b>马氏距离</b><b>(Mahalanobis
Distance)</b></span></p>
<p><span style="font-size: 16px;">（1）马氏距离定义</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 有M个样本向量X1~Xm，协方差矩阵记为S，均值记为向量μ，则其中样本向量X到u的马氏距离表示为：</span></p>
<p><span style="font-size: 16px;"><b>&nbsp;<img src="./机器学习算法那些事_files/2011030823274286.png" style="display: block; margin-left: auto; margin-right: auto;"></b></span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 而其中向量Xi与Xj之间的马氏距离定义为：</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823280193.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 若协方差矩阵是单位矩阵（各个样本向量之间独立同分布）,则公式就成了：</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823281650.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 也就是欧氏距离了。</span></p>
<p><span style="font-size: 16px;">　　若协方差矩阵是对角矩阵，公式变成了标准化欧氏距离。</span></p>
<p><span style="font-size: 16px;">(2)马氏距离的优缺点：量纲无关，排除变量之间的相关性的干扰。</span></p>
<p><span style="font-size: 16px;">(3)
Matlab计算(1 2)，( 1 3)，( 2 2)，( 3 1)两两之间的马氏距离</span></p>
<p align="left" style="padding-left: 30px;"><span style="font-size: 16px;">X = [1 2; 1 3; 2 2; 3 1]</span></p>
<p align="left" style="padding-left: 30px;"><span style="font-size: 16px;">Y = pdist(X,'mahalanobis')</span></p>
<p align="left" style="padding-left: 30px;">&nbsp;</p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">结果：</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">Y
=</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp; 2.3452&nbsp;&nbsp;&nbsp;
2.0000&nbsp;&nbsp;&nbsp; 2.3452&nbsp;&nbsp;&nbsp; 1.2247&nbsp;&nbsp;&nbsp;
2.4495&nbsp;&nbsp;&nbsp; 1.2247</span></p>
<p style="padding-left: 30px;">&nbsp;</p>
<p style="padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>7. </b><b>夹角余弦</b><b>(Cosine)</b></span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 有没有搞错，又不是学几何，怎么扯到夹角余弦了？各位看官稍安勿躁。几何中夹角余弦可用来衡量两个向量方向的差异，机器学习中借用这一概念来衡量样本向量之间的差异。</span></p>
<p><span style="font-size: 16px;">(1)在二维空间中向量A(x1,y1)与向量B(x2,y2)的夹角余弦公式：</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823283429.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">(2)
两个n维样本点a(x11,x12,…,x1n)和b(x21,x22,…,x2n)的夹角余弦</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 类似的，对于两个n维样本点a(x11,x12,…,x1n)和b(x21,x22,…,x2n)，可以使用类似于夹角余弦的概念来衡量它们间的相似程度。</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823293892.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">　　即：</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823294588.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 夹角余弦取值范围为[-1,1]。夹角余弦越大表示两个向量的夹角越小，夹角余弦越小表示两向量的夹角越大。当两个向量的方向重合时夹角余弦取最大值1，当两个向量的方向完全相反夹角余弦取最小值-1。</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 夹角余弦的具体应用可以参阅参考文献[1]。</span></p>
<p><span style="font-size: 16px;">(3)Matlab计算夹角余弦</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">例子：计算(1,0)、( 1,1.732)、(
-1,0)两两间的夹角余弦</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">X
= [1 0 ; 1 1.732 ; -1 0]</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
= 1- pdist(X, 'cosine')&nbsp; % Matlab中的pdist(X,
'cosine')得到的是1减夹角余弦的值</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">结果：</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
=</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp; 0.5000&nbsp;&nbsp;
-1.0000&nbsp;&nbsp; -0.5000</span></p>
<p style="padding-left: 30px;">&nbsp;</p>
<p style="padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>8. </b><b>汉明距离</b><b>(Hamming
distance)</b></span></p>
<p><span style="font-size: 16px;">(1)汉明距离的定义</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 两个等长字符串s1与s2之间的汉明距离定义为将其中一个变为另外一个所需要作的最小替换次数。例如字符串“1111”与“1001”之间的汉明距离为2。</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 应用：信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大）。</span></p>
<p><span style="font-size: 16px;">(2)Matlab计算汉明距离</span></p>
<p><span style="font-size: 16px;">　　Matlab中2个向量之间的汉明距离的定义为2个向量不同的分量所占的百分比。</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 例子：计算向量(0,0)、(1,0)、(0,2)两两间的汉明距离</span></p>
<p align="left" style="padding-left: 30px;"><span style="font-size: 16px;">X = [0 0 ; 1 0 ; 0 2];</span></p>
<p align="left" style="padding-left: 30px;"><span style="font-size: 16px;">D = PDIST(X, 'hamming') </span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">结果：</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
=</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp; 0.5000&nbsp;&nbsp;&nbsp;
0.5000&nbsp;&nbsp;&nbsp; 1.0000</span></p>
<p style="padding-left: 30px;">&nbsp;</p>
<p style="padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>9. </b><b>杰卡德相似系数</b><b>(Jaccard
similarity coefficient)</b></span></p>
<p><span style="font-size: 16px;">(1) 杰卡德相似系数</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号J(A,B)表示。</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823303566.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">　　杰卡德相似系数是衡量两个集合的相似度一种指标。</span></p>
<p><span style="font-size: 16px;">(2) 杰卡德距离</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 与杰卡德相似系数相反的概念是<b>杰卡德距离</b><b>(</b>Jaccard
distance)。杰卡德距离可用如下公式表示：</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823310119.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">　　杰卡德距离用两个集合中不同元素占所有元素的比例来衡量两个集合的区分度。</span></p>
<p><span style="font-size: 16px;">(3)
杰卡德相似系数与杰卡德距离的应用</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 可将杰卡德相似系数用在衡量样本的相似度上。</span></p>
<p><span style="font-size: 16px;">　　样本A与样本B是两个n维向量，而且所有维度的取值都是0或1。例如：A(0111)和B(1011)。我们将样本看成是一个集合，1表示集合包含该元素，0表示集合不包含该元素。</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">p
：样本A与B都是1的维度的个数</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">q
：样本A是1，样本B是0的维度的个数</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">r
：样本A是0，样本B是1的维度的个数</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">s
：样本A与B都是0的维度的个数</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">那么样本A与B的杰卡德相似系数可以表示为：</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">这里p+q+r可理解为A与B的并集的元素个数，而p是A与B的交集的元素个数。</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">而样本A与B的杰卡德距离表示为：</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823313638.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">(4)Matlab
计算杰卡德距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">Matlab的pdist函数定义的杰卡德距离跟我这里的定义有一些差别，Matlab中将其定义为不同的维度的个数占“非全零维度”的比例。</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">例子：计算(1,1,0)、(1,-1,0)、(-1,1,0)两两之间的杰卡德距离</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">X
= [1 1 0; 1 -1 0; -1 1 0]</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
= pdist( X , 'jaccard')</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">结果</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
=</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">0.5000&nbsp;&nbsp;&nbsp; 0.5000&nbsp;&nbsp;&nbsp;
1.0000</span></p>
<p style="padding-left: 30px;">&nbsp;</p>
<p style="padding-left: 30px;"><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>10. </b><b>相关系数</b><b>
( Correlation coefficient )</b><b>与相关距离</b><b>(Correlation distance)</b></span></p>
<p><span style="font-size: 16px;">(1)
相关系数的定义</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823322444.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">相关系数是衡量随机变量X与Y相关程度的一种方法，相关系数的取值范围是[-1,1]。相关系数的绝对值越大，则表明X与Y相关度越高。当X与Y线性相关时，相关系数取值为1（正线性相关）或-1（负线性相关）。</span></p>
<p><span style="font-size: 16px;">(2)相关距离的定义</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823323390.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p align="center">&nbsp;</p>
<p align="left"><span style="font-size: 16px;">(3)Matlab计算(1, 2 ,3 ,4 )与( 3 ,8 ,7 ,6 )之间的相关系数与相关距离</span></p>
<p align="left" style="padding-left: 30px;"><span style="font-size: 16px;">X = [1 2 3 4 ; 3 8 7 6]</span></p>
<p align="left" style="padding-left: 30px;"><span style="font-size: 16px;">C = corrcoef( X' ) &nbsp;&nbsp;%将返回相关系数矩阵</span></p>
<p align="left" style="padding-left: 30px;"><span style="font-size: 16px;">D = pdist( X , 'correlation') </span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">结果：</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">C
=</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp; 1.0000&nbsp;&nbsp;&nbsp;
0.4781</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp; 0.4781&nbsp;&nbsp;&nbsp;
1.0000</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">D
=</span></p>
<p style="padding-left: 30px;"><span style="font-size: 16px;">0.5219</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 其中0.4781就是相关系数，0.5219是相关距离。</span></p>
<p><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>11. </b><b>信息熵</b><b>(</b>Information Entropy)</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 信息熵并不属于一种相似性度量。那为什么放在这篇文章中啊？这个。。。我也不知道。 (╯▽╰)</span></p>
<p><span style="font-size: 16px;">信息熵是衡量分布的混乱程度或分散程度的一种度量。分布越分散(或者说分布越平均)，信息熵就越大。分布越有序（或者说分布越集中），信息熵就越小。</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 计算给定的样本集X的信息熵的公式：</span></p>
<p><span style="font-size: 16px;"><img src="./机器学习算法那些事_files/2011030823325084.png" style="display: block; margin-left: auto; margin-right: auto;"></span></p>
<p><span style="font-size: 16px;">参数的含义：</span></p>
<p><span style="font-size: 16px;">n：样本集X的分类数</span></p>
<p><span style="font-size: 16px;">pi：X中第i类元素出现的概率</span></p>
<p><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 信息熵越大表明样本集S分类越分散，信息熵越小则表明样本集X分类越集中。。当S中n个分类出现的概率一样大时（都是1/n），信息熵取最大值log<sub>2</sub>(n)。当X只有一个分类时，信息熵取最小值0</span></p>
<p><span style="font-size: 16px;"><br></span></p>
<p><span style="font-size: 16px;"><b>参考资料：</b><b>&nbsp;</b></span></p>
<p><span style="font-size: 16px;">[1]吴军. 数学之美 系列 12 -
余弦定理和新闻的分类.</span></p>
<p><span style="font-size: 16px;"><a href="http://www.google.com.hk/ggblog/googlechinablog/2006/07/12_4010.html">http://www.google.com.hk/ggblog/googlechinablog/2006/07/12_4010.html</a></span></p>
<p><span style="font-size: 16px;">[2]
Wikipedia. Jaccard index. </span></p>
<p><span style="font-size: 16px;"><a href="http://en.wikipedia.org/wiki/Jaccard_index">http://en.wikipedia.org/wiki/Jaccard_index</a></span></p>
<p><span style="font-size: 16px;">[3]
Wikipedia. Hamming distance</span></p>
<p><span style="font-size: 16px;"><a href="http://en.wikipedia.org/wiki/Hamming_distance">http://en.wikipedia.org/wiki/Hamming_distance</a></span></p>
<p><span style="font-size: 16px;">[4] 求马氏距离（Mahalanobis
distance ）matlab版</span></p>
<p><span style="font-size: 16px;"><a href="http://junjun0595.blog.163.com/blog/static/969561420100633351210/">http://junjun0595.blog.163.com/blog/static/969561420100633351210/</a></span></p>
<p><span style="font-size: 16px;">[5] Pearson product-moment
correlation coefficient</span></p>
<p><span style="font-size: 16px;"><a href="http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient">http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient</a></span></p>
<p><span style="font-size: 16px;"><br></span></p></div><div id="MySignature"></div>
<div class="clear"></div>
<div id="blog_post_info_block">
<div id="BlogPostCategory">分类: <a href="https://www.cnblogs.com/heaad/category/272649.html" target="_blank">机器学习</a></div>
<div id="EntryTag"></div>
<div id="blog_post_info"><div id="green_channel">
        <a href="javascript:void(0);" id="green_channel_digg" onclick="DiggIt(1977733,cb_blogId,1);green_channel_success(this,&#39;谢谢推荐！&#39;);">好文要顶</a>
            <a id="green_channel_follow" onclick="follow(&#39;323033f4-1936-de11-9510-001cf0cd104b&#39;);" href="javascript:void(0);">关注我</a>
    <a id="green_channel_favorite" onclick="AddToWz(cb_entryId);return false;" href="javascript:void(0);">收藏该文</a>
    <a id="green_channel_weibo" href="javascript:void(0);" title="分享至新浪微博" onclick="ShareToTsina()"><img src="./机器学习算法那些事_files/icon_weibo_24.png" alt=""></a>
    <a id="green_channel_wechat" href="javascript:void(0);" title="分享至微信" onclick="shareOnWechat()"><img src="./机器学习算法那些事_files/wechat.png" alt=""></a>
</div>
<div id="author_profile">
    <div id="author_profile_info" class="author_profile_info">
            <a href="http://home.cnblogs.com/u/heaad/" target="_blank"><img src="./机器学习算法那些事_files/u63234.png" class="author_avatar" alt=""></a>
        <div id="author_profile_detail" class="author_profile_info">
            <a href="http://home.cnblogs.com/u/heaad/">苍梧</a><br>
            <a href="http://home.cnblogs.com/u/heaad/followees">关注 - 2</a><br>
            <a href="http://home.cnblogs.com/u/heaad/followers">粉丝 - 1053</a>
        </div>
    </div>
    <div class="clear"></div>
    <div id="author_profile_honor"></div>
    <div id="author_profile_follow">
                <a href="javascript:void(0);" onclick="follow(&#39;323033f4-1936-de11-9510-001cf0cd104b&#39;);return false;">+加关注</a>
    </div>
</div>
<div id="div_digg">
    <div class="diggit" onclick="votePost(1977733,&#39;Digg&#39;)">
        <span class="diggnum" id="digg_count">21</span>
    </div>
    <div class="buryit" onclick="votePost(1977733,&#39;Bury&#39;)">
        <span class="burynum" id="bury_count">0</span>
    </div>
    <div class="clear"></div>
    <div class="diggword" id="digg_tips">
    </div>
</div>
<script type="text/javascript">
    currentDiggType = 0;
</script></div>
<div class="clear"></div>
<div id="post_next_prev"><a href="https://www.cnblogs.com/heaad/archive/2011/03/07/1976443.html" class="p_n_p_prefix">« </a> 上一篇：<a href="https://www.cnblogs.com/heaad/archive/2011/03/07/1976443.html" title="发布于2011-03-07 22:30">神经网络编程入门</a><br><a href="https://www.cnblogs.com/heaad/archive/2011/03/09/1978254.html" class="p_n_p_prefix">» </a> 下一篇：<a href="https://www.cnblogs.com/heaad/archive/2011/03/09/1978254.html" title="发布于2011-03-09 13:43">Let’s Play Games!</a><br></div>
</div>

</div>
	</div></div><a name="!comments"></a><div id="blog-comments-placeholder"><div id="comments_pager_top"></div>
<h3>Feedback</h3>
	
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2170702" class="layer">#1楼</a><a name="2170702" id="comment_anchor_2170702"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2011-08-07 18:57</span> by <a id="a_comment_author_2170702" href="http://home.cnblogs.com/u/321811/" target="_blank">感冒灵颗粒</a> <a href="http://msg.cnblogs.com/send/%E6%84%9F%E5%86%92%E7%81%B5%E9%A2%97%E7%B2%92" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_2170702" class="blog_comment_body">楼主，请问你是什么专业的啊？</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2170702,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2170702,&#39;Bury&#39;,this)">反对(0)</a></div></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2183184" class="layer">#2楼</a><a name="2183184" id="comment_anchor_2183184"></a>[<span class="louzhu">楼主</span>]
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2011-08-22 21:14</span> by <a id="a_comment_author_2183184" href="https://www.cnblogs.com/heaad/" target="_blank">苍梧</a> <a href="http://msg.cnblogs.com/send/%E8%8B%8D%E6%A2%A7" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_2183184" class="blog_comment_body"><a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2170702" title="查看所回复的评论" onclick="commentManager.renderComments(0,50,2170702);">@</a>
感冒灵颗粒<br>计算机</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2183184,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2183184,&#39;Bury&#39;,this)">反对(0)</a></div><span id="comment_2183184_avatar" style="display:none;">http://pic.cnblogs.com/face/u63234.png</span></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2250433" class="layer">#3楼</a><a name="2250433" id="comment_anchor_2250433"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2011-11-22 11:07</span> by <a id="ctl00_CommentList_NameLink_2" title="未注册用户" target="_blank">ssfa</a>
				</div>
				<div class="postbody"><div id="comment_body_2250433" class="blog_comment_body">灰常有用 ~~ 多谢楼主 </div></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2326952" class="layer">#4楼</a><a name="2326952" id="comment_anchor_2326952"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2012-03-09 17:27</span> by <a id="a_comment_author_2326952" href="http://home.cnblogs.com/u/381390/" target="_blank">苏州河8808</a> <a href="http://msg.cnblogs.com/send/%E8%8B%8F%E5%B7%9E%E6%B2%B38808" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_2326952" class="blog_comment_body">支持！！！</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2326952,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2326952,&#39;Bury&#39;,this)">反对(0)</a></div></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2328269" class="layer">#5楼</a><a name="2328269" id="comment_anchor_2328269"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2012-03-12 09:46</span> by <a id="a_comment_author_2328269" href="http://home.cnblogs.com/u/381515/" target="_blank">janice2data</a> <a href="http://msg.cnblogs.com/send/janice2data" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_2328269" class="blog_comment_body">受益匪浅</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2328269,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2328269,&#39;Bury&#39;,this)">反对(0)</a></div></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2380462" class="layer">#6楼</a><a name="2380462" id="comment_anchor_2380462"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2012-05-19 11:37</span> by <a id="a_comment_author_2380462" href="http://home.cnblogs.com/u/394634/" target="_blank">zoezheng</a> <a href="http://msg.cnblogs.com/send/zoezheng" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_2380462" class="blog_comment_body">泪流满面</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2380462,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2380462,&#39;Bury&#39;,this)">反对(0)</a></div></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2380463" class="layer">#7楼</a><a name="2380463" id="comment_anchor_2380463"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2012-05-19 11:39</span> by <a id="a_comment_author_2380463" href="http://home.cnblogs.com/u/394634/" target="_blank">zoezheng</a> <a href="http://msg.cnblogs.com/send/zoezheng" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_2380463" class="blog_comment_body">请问任何两种分布之间的距离应该怎么算呢？ 毕设不会啊~</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2380463,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2380463,&#39;Bury&#39;,this)">反对(0)</a></div></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2381572" class="layer">#8楼</a><a name="2381572" id="comment_anchor_2381572"></a>[<span class="louzhu">楼主</span>]
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2012-05-21 13:52</span> by <a id="a_comment_author_2381572" href="https://www.cnblogs.com/heaad/" target="_blank">苍梧</a> <a href="http://msg.cnblogs.com/send/%E8%8B%8D%E6%A2%A7" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_2381572" class="blog_comment_body"><a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2380463" title="查看所回复的评论" onclick="commentManager.renderComments(0,50,2380463);">@</a>
zoezheng<br>可以查一下 KL 距离。估计对你有帮助</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2381572,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2381572,&#39;Bury&#39;,this)">反对(0)</a></div><span id="comment_2381572_avatar" style="display:none;">http://pic.cnblogs.com/face/u63234.png</span></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2472109" class="layer">#9楼</a><a name="2472109" id="comment_anchor_2472109"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2012-09-13 16:44</span> by <a id="a_comment_author_2472109" href="https://www.cnblogs.com/lsws33/" target="_blank">Wall^E</a> <a href="http://msg.cnblogs.com/send/Wall%5EE" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_2472109" class="blog_comment_body">您的公式用什么录入的</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2472109,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2472109,&#39;Bury&#39;,this)">反对(0)</a></div><span id="comment_2472109_avatar" style="display:none;">http://pic.cnblogs.com/face/u278255.bmp?id=13193735</span></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2593218" class="layer">#10楼</a><a name="2593218" id="comment_anchor_2593218"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2013-01-05 22:18</span> by <a id="a_comment_author_2593218" href="https://www.cnblogs.com/yulele/" target="_blank">于乐乐</a> <a href="http://msg.cnblogs.com/send/%E4%BA%8E%E4%B9%90%E4%B9%90" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_2593218" class="blog_comment_body">真好，顶</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2593218,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2593218,&#39;Bury&#39;,this)">反对(0)</a></div><span id="comment_2593218_avatar" style="display:none;">http://pic.cnblogs.com/face/337284/20150206153108.png</span></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#2632189" class="layer">#11楼</a><a name="2632189" id="comment_anchor_2632189"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2013-03-11 13:50</span> by <a id="a_comment_author_2632189" href="http://home.cnblogs.com/u/503328/" target="_blank">smartmcu</a> <a href="http://msg.cnblogs.com/send/smartmcu" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_2632189" class="blog_comment_body">太有才了！！！<br>您要是适龄女士，俺准备追求您，娶您！</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2632189,&#39;Digg&#39;,this)">支持(3)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2632189,&#39;Bury&#39;,this)">反对(0)</a></div></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#3051034" class="layer">#12楼</a><a name="3051034" id="comment_anchor_3051034"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2014-10-25 16:35</span> by <a id="a_comment_author_3051034" href="http://home.cnblogs.com/u/458970/" target="_blank">xiaoYY</a> <a href="http://msg.cnblogs.com/send/xiaoYY" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_3051034" class="blog_comment_body">顶，谢谢博主</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(3051034,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(3051034,&#39;Bury&#39;,this)">反对(0)</a></div></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#3249772" class="layer">#13楼</a><a name="3249772" id="comment_anchor_3249772"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2015-08-18 16:03</span> by <a id="a_comment_author_3249772" href="https://www.cnblogs.com/conard/" target="_blank">conard</a> <a href="http://msg.cnblogs.com/send/conard" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_3249772" class="blog_comment_body">杰卡德相似系数那里的例子应该算的是相似系数而不是距离</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(3249772,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(3249772,&#39;Bury&#39;,this)">反对(0)</a></div><span id="comment_3249772_avatar" style="display:none;">http://pic.cnblogs.com/face/400262/20150902145803.png</span></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#3455356" class="layer">#14楼</a><a name="3455356" id="comment_anchor_3455356"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2016-06-20 10:54</span> by <a id="a_comment_author_3455356" href="https://www.cnblogs.com/studytesting/" target="_blank">奋斗成就未来!</a> <a href="http://msg.cnblogs.com/send/%E5%A5%8B%E6%96%97%E6%88%90%E5%B0%B1%E6%9C%AA%E6%9D%A5%21" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_3455356" class="blog_comment_body">有才之人。</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(3455356,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(3455356,&#39;Bury&#39;,this)">反对(0)</a></div><span id="comment_3455356_avatar" style="display:none;">http://pic.cnblogs.com/face/104093/20130503141257.png</span></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#3474237" class="layer">#15楼</a><a name="3474237" id="comment_anchor_3474237"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2016-07-21 15:51</span> by <a id="a_comment_author_3474237" href="https://www.cnblogs.com/whatbeg/" target="_blank">whatbeg</a> <a href="http://msg.cnblogs.com/send/whatbeg" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_3474237" class="blog_comment_body">mark！</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(3474237,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(3474237,&#39;Bury&#39;,this)">反对(0)</a></div><span id="comment_3474237_avatar" style="display:none;">http://pic.cnblogs.com/face/591194/20141215104354.png</span></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#3703513" class="layer">#16楼</a><a name="3703513" id="comment_anchor_3703513"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2017-05-30 18:43</span> by <a id="a_comment_author_3703513" href="http://home.cnblogs.com/u/1153906/" target="_blank">有一条鱼</a> <a href="http://msg.cnblogs.com/send/%E6%9C%89%E4%B8%80%E6%9D%A1%E9%B1%BC" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_3703513" class="blog_comment_body">好东西</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(3703513,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(3703513,&#39;Bury&#39;,this)">反对(0)</a></div></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#3791093" class="layer">#17楼</a><a name="3791093" id="comment_anchor_3791093"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2017-09-20 16:17</span> by <a id="a_comment_author_3791093" href="https://www.cnblogs.com/xufun/" target="_blank">xufun</a> <a href="http://msg.cnblogs.com/send/xufun" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_3791093" class="blog_comment_body">好文，拜读学习了。<br>谢谢！</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(3791093,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(3791093,&#39;Bury&#39;,this)">反对(0)</a></div><span id="comment_3791093_avatar" style="display:none;">http://pic.cnblogs.com/face/u74964.jpg</span></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#3793694" class="layer">#18楼</a><a name="3793694" id="comment_anchor_3793694"></a>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2017-09-22 17:53</span> by <a id="a_comment_author_3793694" href="https://www.cnblogs.com/vincent-vg/" target="_blank">WOTGL</a> <a href="http://msg.cnblogs.com/send/WOTGL" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_3793694" class="blog_comment_body">请问博主，标准化欧氏距离公式中的Sk是什么？</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(3793694,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(3793694,&#39;Bury&#39;,this)">反对(0)</a></div></div>
			</div>
		
			<div class="post">
				<div class="posthead">
					<h2>
						<a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#3830501" class="layer">#19楼</a><a name="3830501" id="comment_anchor_3830501"></a><span id="comment-maxId" style="display:none;">3830501</span><span id="comment-maxDate" style="display:none;">2017/11/3 21:15:59</span>
						&nbsp;&nbsp;<span class="comment_actions"></span>
					</h2>
					 <span class="comment_date">2017-11-03 21:15</span> by <a id="a_comment_author_3830501" href="http://home.cnblogs.com/u/1258673/" target="_blank">就酱</a> <a href="http://msg.cnblogs.com/send/%E5%B0%B1%E9%85%B1" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
				</div>
				<div class="postbody"><div id="comment_body_3830501" class="blog_comment_body">好文，谢谢了</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(3830501,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(3830501,&#39;Bury&#39;,this)">反对(0)</a></div></div>
			</div>
		<div id="comments_pager_bottom"></div></div><script type="text/javascript">var commentManager = new blogCommentManager();commentManager.renderComments(0);</script>
<div id="comment_form" class="commentform">
<a name="commentform"></a>
<div id="divCommentShow"></div>
<div id="comment_nav"><span id="span_refresh_tips"></span><a href="javascript:void(0);" onclick="return RefreshCommentList();" id="lnk_RefreshComments" runat="server" clientidmode="Static">刷新评论</a><a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#" onclick="return RefreshPage();">刷新页面</a><a href="https://www.cnblogs.com/heaad/archive/2011/03/08/1977733.html#top">返回顶部</a></div>
<div id="comment_form_container"><div class="login_tips">注册用户登录后才能发表评论，请 <a rel="nofollow" href="javascript:void(0);" class="underline" onclick="return login(&#39;commentform&#39;);">登录</a> 或 <a rel="nofollow" href="javascript:void(0);" class="underline" onclick="return register();">注册</a>，<a href="http://www.cnblogs.com/">访问</a>网站首页。</div></div>
<div class="ad_text_commentbox" id="ad_text_under_commentbox"></div>
<div id="ad_t2"><a href="http://www.ucancode.com/index.htm" target="_blank">【推荐】超50万VC++源码: 大型组态工控、电力仿真CAD与GIS源码库！</a><br><a href="http://clickc.admaster.com.cn/c/a116493,b2949399,c1705,i0,m101,8a1,8b3,h" target="_blank" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;T2-华为云&#39;)">【活动】申请成为华为云云享专家 尊享9大权益</a><br><a href="https://www.grapecity.com.cn/developer/spreadjs?utm_source=cnblogs&amp;utm_medium=blogpage&amp;utm_term=bottom&amp;utm_content=SpreadJS&amp;utm_campaign=community" target="_blank" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;T2-SpreadJS&#39;)">【工具】SpreadJS纯前端表格控件，可嵌入应用开发的在线Excel</a><br><a href="https://cloud.tencent.com/act/group/amd/index?fromSource=gwzcw.1608278.1608278.1608278" target="_blank" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;T2-腾讯云&#39;)">【腾讯云】拼团福利，AMD云服务器8元/月</a><br></div>
<div id="opt_under_post"></div>
<div id="cnblogs_c1" class="c_ad_block"><a href="https://cloud.tencent.com/act/double11?fromSource=gwzcw.1608279.1608279.1608279" target="_blank"><img width="300" height="250" src="./机器学习算法那些事_files/24442-20181116205423366-85420768.jpg" alt="qcloud" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;C1&#39;);"></a></div>
<div id="under_post_news"><div class="itnews c_ad_block"><b>相关博文：</b><br>·  <a href="https://www.cnblogs.com/yyxayz/p/4321456.html" target="_blank" onclick="clickRecomItmem(4321456,&#39;MS6z01LpcuQJnFGFmCPu+KhjOxanJaszeTrj7ZaAHIu1fVCkZmRNgc+b/p2btULnrNl21WhBReTqkYLhJIrUXymhvYD6M1M6JP/8cpfaP+6GSXsDmFC7IBxHozsqLy9Fla0GD8PBc7PalR6uXO6e92Eoqw4n+iQYB2dZrvVtDuQFwb7o&#39;)">机器学习中的距离度量</a><br>·  <a href="https://www.cnblogs.com/xbinworld/archive/2012/09/24/2700572.html" target="_blank" onclick="clickRecomItmem(2700572,&#39;5Rd2stl1+Offf3iAM4nUpQIIiPakxOx4YWQVOiMtP6Z4sQRyrxXGUVDY5iLsNxSfHQPQZdLuBFloeti4Z5iQoIzjqHePsBD57kBjNn15mFEoNBXQm3yR2UNpUTYfwqy9JkCYisZTWNuOeGPpSO5JDqlfjr4rCMV+FU00UWgvBUvqbw==&#39;)">距离计算方法总结</a><br>·  <a href="https://www.cnblogs.com/liujinhong/p/6001997.html" target="_blank" onclick="clickRecomItmem(6001997,&#39;Mg9uWDvGGXQ2xioV/dCjJswbRX7zwj6B2JKHa60fgjMIA5tGr5WksUDSjAoF7aJiWQuzuwW7vwrPeWTkyP0ofd43G9y3XPL2uY7EU2KZcnz2fstJz50nhadmpRlMvYT34/NRQxB+1SaiPswtpvQvOeUmIXvswWKQetvYqG/1MqP2tNpA&#39;)">向量的相似性度量</a><br>·  <a href="https://www.cnblogs.com/sason/p/5590228.html" target="_blank" onclick="clickRecomItmem(5590228,&#39;UBnC/yx/BMH9CZfIX6xLfBOWQ3qyl2wnzxaSJ2U/KuB6Ud9C3CjQIAQpTfVIWih2I+HVp4Ja8roUWZHa5frZNgrVT8Guve9tOhckSAedmu9vOcGn0u9kr9d1+NpkWPNA1USaGRxeT9TJTrnbZf2g922p45OIttqed6syfSVyS8Y8SIlS&#39;)">各种距离分析</a><br>·  <a href="https://www.cnblogs.com/duanchw-37/archive/2012/08/24/2654019.html" target="_blank" onclick="clickRecomItmem(2654019,&#39;4w3UHdVsMGjNU0eiLJSmd7H1D8CqvifTTfWuSb6cdOfRqx7Qziu3XJZy1h/q+rc3bNoOtahB0x8KT29NZXxN202vywmyb0fc6i5ITldKt0aJxEa8rEVqiUo2wxeanUjQUreFkvW4WQ2yICd8iClJ1zPGBW6dIBMB+o5VdZhCcHK/UUKuUo1uWxOcfPqo6y0sbA==&#39;)">相似性度量的方法总结</a><br></div></div>
<script async="async" src="./机器学习算法那些事_files/gpt.js"></script>
<script>
  var googletag = googletag || {};
  googletag.cmd = googletag.cmd || [];
</script>

<script>
  googletag.cmd.push(function() {
    googletag.defineSlot('/1090369/C2', [468, 60], 'div-gpt-ad-1539008685004-0').addService(googletag.pubads());
    googletag.pubads().enableSingleRequest();
    googletag.enableServices();
  });
</script>
<div id="cnblogs_c2" class="c_ad_block">
    <div id="div-gpt-ad-1539008685004-0" style="height:60px; width:468px;" data-google-query-id="CPiyxqTO8d4CFZAYKgodBaIKxQ">
    <script>
    if (new Date() >= new Date(2018, 9, 13)) {
        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1539008685004-0'); });
    }
    </script>
    <div id="google_ads_iframe_/1090369/C2_0__container__" style="border: 0pt none;"><iframe id="google_ads_iframe_/1090369/C2_0" title="3rd party ad content" name="google_ads_iframe_/1090369/C2_0" width="468" height="60" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" style="border: 0px; vertical-align: bottom;" data-google-container-id="1" data-load-complete="true" src="./机器学习算法那些事_files/saved_resource.html"></iframe></div></div>
</div>
<div id="under_post_kb"><div class="itnews c_ad_block"><b>最新新闻</b>：<br> ·  <a href="https://news.cnblogs.com/n/613210/" target="_blank">历史进程中的两轮电动车</a><br> ·  <a href="https://news.cnblogs.com/n/613240/" target="_blank">“双面”少儿编程：一边疯狂挤入，一边狼狈退出</a><br> ·  <a href="https://news.cnblogs.com/n/613243/" target="_blank">庆祝国际空间站20周年 宇航员发布15分钟延时摄影作品</a><br> ·  <a href="https://news.cnblogs.com/n/613242/" target="_blank">刘立荣沉浮录：百亿赌债成谜，金立手机绝地求生</a><br> ·  <a href="https://news.cnblogs.com/n/613239/" target="_blank">没有名校光环，他是如何拯救无数生命并拿到诺奖</a><br>» <a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">更多新闻...</a></div></div>
<div id="HistoryToday" class="c_ad_block"></div>
<script type="text/javascript">
    fixPostBody();
    setTimeout(function () { incrementViewCount(cb_entryId); }, 50);
    deliverAdT2();
    deliverAdC1();
    deliverAdC2();    
    loadNewsAndKb();
    loadBlogSignature();
    LoadPostInfoBlock(cb_blogId, cb_entryId, cb_blogApp, cb_blogUserGuid);
    GetPrevNextPost(cb_entryId, cb_blogId, cb_entryCreatedDate, cb_postType);
    loadOptUnderPost();
    GetHistoryToday(cb_blogId, cb_blogApp, cb_entryCreatedDate);   
</script>
</div>


			</div>
		</td>
	</tr>
	<tr>
		<td colspan="2" class="FooterCell">
			
<p id="footer">
	Powered by: 
	<br>
	
	<a id="Footer1_Hyperlink3" name="Hyperlink1" href="https://www.cnblogs.com/" style="font-family:Verdana;font-size:12px;">博客园</a>
	<br>
	Copyright © 苍梧
</p>
		</td>
	</tr>
</tbody></table>




<iframe id="google_osd_static_frame_6682841465693" name="google_osd_static_frame" style="display: none; width: 0px; height: 0px;" src="./机器学习算法那些事_files/saved_resource(1).html"></iframe></body></html>